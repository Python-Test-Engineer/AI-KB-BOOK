{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Powered Knowledge Systems","text":""},{"location":"#mission","title":"Mission","text":"<p>To create a Software as a Service, (SASS), product that enable the medical community to harness the power of AI to improve extraction and presentation of relevent, accurate and complete information from the vast amount of data available in the medical literature.</p>"},{"location":"#current_concepts","title":"Current concepts","text":"<p>What are the current concepts/buzz words in this space?</p>"},{"location":"#llm","title":"LLM","text":"<p>A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data \u2014 hence the name \"large.\" LLMs are built on machine learning: specifically, a type of neural network called a transformer model.</p> <p>We represent it in our architecture as a brain and this serves us well as we can also think what would a human do at this stage?</p> <p></p>"},{"location":"#vector_databases","title":"Vector Databases","text":"<p>OpenAI has 1536 dimensions</p>"},{"location":"#semantic_search","title":"Semantic search","text":"<p>Semantic search vectors are numerical representations of data and related contexts that are used to rank and deliver search results based on their relevance. </p> <p>The closer two points in vector space are, the more similar they are.</p> <p>There are a few different methods such as cosine similarity, dot product, Euclidean distance etc.</p>"},{"location":"#rag","title":"RAG","text":"<p>RAG = Retrieval Augmented Generation</p> <p>RETRIEVAL:</p> <p>We retrieve the most useful information from a vector database and then use it to generate a response using the LLM.</p> <p>AUGEMENTED:</p> <p>We combine the retreived documents and the query and pass it to the LLM to generate a response.</p> <p>GENERATION:</p> <p>The LLM generates the final response.</p>"},{"location":"#prompt_engineering","title":"Prompt Engineering","text":"<p>There is a difference between sending the documents and query to the LLM as is and a prompt template:</p> <p>\"You are an expert in the field of medicine. Answer the following question: {question} based on the following documents: {documents}\"</p> <p>If you are unsure about your answer, say \"I don't know\".</p> <p>Use a professional and formal language in your responses.</p> <p>Where possible, use references from the documents.</p> <p>I like to thing of it as giving an actor details about a scene or giving a detailed job description to an researcher.</p>"},{"location":"#ai_agents","title":"AI Agents","text":"<p>An artificial intelligence (AI) agent is a software program that can interact with its environment, collect data, and use the data to perform self-determined tasks to meet predetermined goals. Humans set goals, but an AI agent independently chooses the best actions it needs to perform to achieve those goals. For example, consider a contact center AI agent that wants to resolves customer queries. The agent will automatically ask the customer different questions, look up information in internal documents, and respond with a solution. Based on the customer responses, it determines if it can resolve the query itself or pass it on to a human.</p> <p>Whilst we may have our overall flowchart, the AI Agent will determine the path to take. It is like having the roll of a dice determine the next step. We have a predetermined set of tasks, but the agent will determine the best way to complete those tasks.</p>"},{"location":"#naive_rag","title":"Naive Rag","text":"<p>Two years ago when we first looked at RAG, the strategy was to take a document and split into chuncks of say 500 characters and have an overlap of 100 charactes with the next chunk to maintain some context.</p> <p>This works very well for single modality text documents where this Niave Rag is in effect a search tool, taking an unstructured query and using LLMs and semantic search to find relevant chunks and answer the question.</p>"},{"location":"#changes_in_2yrs","title":"Changes in 2yrs","text":"<p>In the past two years there have been many changes in the space.</p> <ul> <li>Context windows, the amount of text we can pass to the LLM has grown from 4K to 32K+</li> <li>Compute power has greatly increased, costs have gone donw by 90%.</li> <li>LLMs have become bigger and better, with many specialist LLMs that are fine tuned for particular uses.</li> <li>LLMs can now understand images, tables and videos better, with LLMs that can parse different media and convert them into text.</li> <li>Many frameworks and services for RAG have emerged and 2025 is thought of the year that the question will be which system to use?</li> <li>Naive Rag has been replaced with more sophisticated strategies that involve all aspects of the architecture:</li> </ul> <p>Without needing to understand this next image, here is the current 'state of the art' RAG architecture:</p> <p></p> <p>New academic papers for better techniques are continually being published.</p> <p>\"This is the worst it will ever be...\" - someone said.</p> <p></p>"},{"location":"craig/contact/","title":"Contact me","text":"<p>Email: iwswordpress@gmail.com</p> <p>LinkedIn: Craig West</p>"},{"location":"craig/courses/","title":"Online courses","text":""},{"location":"craig/courses/#udemycom","title":"Udemy.com","text":"<p>The course Udemy Hooks and Plugins course has just been published and Udemy has a sale ever two weeks and the cost would be $20 USD approx.</p> <p></p> <p>I am currently developing two courses:</p> <ul> <li>Python - mock, patch and monkeypatch.</li> <li>PyTest Django Full Stack - a DB &lt;-&gt; E2E testing of a generic ecommerce store.</li> </ul> <p>The aim is to make them generic, ready to go templates, that also dive deeper into aspects of Python.</p> <p>I am of the opinion that as developers we do not need to reinvent the wheel - it has (almost) all been done before - and that we should be free to use our creativity to build great proucts.</p> <p>The type of course I would want...</p> <p></p>"},{"location":"craig/cv/","title":"CV","text":""},{"location":"craig/cv/#github_cv","title":"GitHub CV","text":"<p>I use GitHub to host a copy of my CV.</p> <p>Github CV</p>"},{"location":"craig/cv/#python_backend_and_test_automation_engineer","title":"Python Backend and Test Automation Engineer","text":"<ul> <li>Degree in Chemistry, Oxford University.</li> <li>Former A+ PC Technician, Microsoft Certified Systems Engineer and Microsoft Certified SQL Server DBA.</li> <li>Former Business Information Architect.</li> <li>Qualified Accountant Technician and business owner.</li> <li>Experience with REST APIs, GraphQL, React, Vue, Web Components, Node, Docker</li> <li>Talks and workshops given at WordCamps, MeetUps and NDC.</li> </ul>"},{"location":"craig/cv/#talks_and_workshops","title":"Talks and Workshops","text":"<p>A list of talks and workshops I have given: </p> <ul> <li> <p>TALK: Offline and instant websites, aka Progressive Web Apps - AsyncJS, Brighton, September 2021.</p> </li> <li> <p>LIGHTNING TALK: WordPress as a Micro Service to any framework - WordFest, July 2021.</p> </li> <li> <p>TALK: WP REST API and Web Components =&gt; 100% Internet - WordCamp Santa Clarita, July 2021.</p> </li> <li> <p>TALK: Web Components in WP, Gutenberg and as HTML plugins. - WordCamp North East Ohio May 2021.</p> </li> <li> <p>TALK: Leveraging the power or the WordPress REST API - WP Leeds April 2021</p> </li> <li> <p>WORKSHOP: WP REST API and you -&gt; Best Friends Forever workshop (90 mins) - WordCamp Greece April 2021 </p> </li> <li> <p>TALK: Web Components as Micro Apps - NDC London, Jan 2021</p> </li> <li> <p>TALK: Unifying frameworks with Web Components - Brighton AsyncJS, Nov 2020</p> </li> <li> <p>WORKSHOP: Progressive Web Apps Workshop (2hrs) - NDC Oslo June 2020 and a paid training workshop with NDC</p> </li> <li> <p>WORKSHOP: Web Components Workshop (2hrs) - NDC Oslo June 2020 and a paid training workshope with NDC</p> </li> <li> <p>WORKSHOP: Progressive Web Apps Workshop (2hrs) - Brighton WordUp June 2020</p> </li> <li> <p>WORKSHOP: WordPress REST API with AJAX Forms and Pages - WordCamp Denver, June 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API with AJAX Forms and Pages - WordCamp Kent, Ohio May 2020.</p> </li> <li> <p>TALK: What is the WP REST API and how can I use it to make forms and pages that don\u2019t need to do be reloaded? - WordUp Brighton May 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API and AJAX Forms - WordCamp Geneva March 2020 EVENT CANCELLED due to virus concerns </p> </li> <li> <p>TALK - WP-HTML: The marriage of WP and JS Frameworks for expansion, ubiquity and profit - WordCamp Vienna February 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API - WordCamp Vienna February 2020.</p> </li> <li> <p>TALK: Progressive Web Apps - Brighton WordUp November 2019.</p> </li> <li> <p>TALK: Decoupled WordPress (code along style) - WordCamp Dublin October 2019.</p> </li> <li> <p>TALK: JWT and Authentication - WPHooked London September 2019</p> </li> <li> <p>TALK: Decoupled WordPress and WP Components - WordCamp Brighton August 2019.</p> </li> </ul>"},{"location":"craig/cv/#published_udemy_courses","title":"Published Udemy Courses","text":"<p>Udemy is a great learning platform and having sales at least once a month, courses can be purchased for ~ \u00a315/$15 USD.</p> <p>These have now been retired.</p> <ul> <li>WordPress REST API and AJAX Forms/Pages - DEMO https://www.youtube.com/watch?v=eubhbcGH_Ws&amp;t=6s (paid)</li> <li>Progressive Web Apps - DEMO https://www.youtube.com/watch?v=k_lHvNL0gkw (paid)</li> <li>WP-HTML: decoupling WordPress to any HTML platform using Web Components and the WP REST API. This also enables HTML plugins for non-WP Sites - https://www.udemy.com/course/powerful-html-pages-using-wordpress-component-architecture/ (free)</li> <li>Stylish Dynamic Web Forms with jQuery validation - https://www.udemy.com/course/ready-to-use-form-validation-templates-with-jquery/ (free)</li> </ul>"},{"location":"craig/cv/#youtube_courses_-_developer_to_developer_courses","title":"YouTube Courses - Developer to Developer courses","text":"<p>These are video courses that cover work through official documents to help other developers, learn in public and show prosepective employers not just what I know but how I learn and how I communicate technical matters to others.</p> <p>There are also some specific videos explaining solutions to set ups other developers may encounter.</p> <ul> <li> <p>HIGHLY-FUNCTIONAL-WEBCOMPONENTS: A video course based on the workshop I gave at NDC Oslo June 2020 - https://www.youtube.com/watch?v=QC-JTqQTv2k&amp;list=PLsszRSbzjyvkQwzrJobroRl7z7MfSlePa </p> </li> <li> <p>WP Plugin Boilerplate:  I havea video series to explain WP Plugin Boilerplate using a scaffolded out project that demonstrates the use of MySQL, wp_nonce, REST API, forms and how to redirect pages to plugin templates to make the plugin theme independent. https://www.youtube.com/watch?v=lJ9ktD4JOfs&amp;list=PLsszRSbzjyvn-RQr4dEjrgnTne2HcJKee</p> </li> </ul>"},{"location":"craig/cv/#volunteering","title":"Volunteering","text":"<p>I volunteer at Codebar.io in Brighton as well as some Community Kitchens.</p>"},{"location":"craig/cv/#outside_interests","title":"Outside interests","text":"<p>These include Community Kitchens, gym, occasional partner dancing and DIY.</p> <p></p>"},{"location":"craig/services/","title":"Services provided","text":""},{"location":"craig/services/#backend_pythonista_and_test_automation_engineer","title":"Backend Pythonista and Test Automation Engineer","text":""},{"location":"craig/services/#skillset","title":"Skillset","text":"<p>Primarily:</p> <ul> <li>Python</li> <li>PyTest</li> <li>Playwright</li> <li>Django</li> </ul> <p>Tools:</p> <p>I strive to dive deeper into these tools and see them as programming languages in their own right. DevOps seems to be an essential part of my work:</p> <ul> <li>Shell Scripting</li> <li>Git/GitHub Actions</li> <li>Docker</li> </ul>"},{"location":"craig/services/#engagement_style","title":"Engagement Style","text":"<p>I offer on-demand, freelance services starting from 1/2 day blocks.</p> <p>As and when you need it...</p> <p>Tech is a way of life for me not just a job and I strive to have enthusiasm and passion for the projects I work on. Professional fulfilment is paramount.</p>"},{"location":"craig/services/#eligibility","title":"Eligibility","text":"<ul> <li>UK National</li> <li>Fluent English</li> </ul>"},{"location":"craig/services/#on-sitehybrid","title":"On-site/Hybrid","text":"<p>I am based in Brighton and enjoy (local) on-site work as well as working from my home office.</p>"},{"location":"craig/services/#volunteer_coach","title":"Volunteer Coach","text":"<p>I am a volunteer coach with Codebar Brighton.</p>"},{"location":"craig/services/#youtube","title":"YouTube","text":"<p>I produce a large amount of content that is associated with a repo that enables 'out of the box' ease of use.</p> <p>If I find good videos without a repo, I often create a repo and my own video with reference to the source video. I have no commercial interest in this matter.</p> <p>My YouTube Channel</p>"},{"location":"craig/services/#outside_of_tech","title":"Outside of tech...","text":"<p>I enjoy working in community kitchens and love laughter, creating, doing and trying to work out why things are funny.</p> <p></p>"},{"location":"evaluation/domain_expert/","title":"Professional Evaluation","text":"<p>The technique of an (untested) LLm generating question/answer pairs to act as ground truths to then test an LLM seems illogical but current thinking states this is quite effective.</p> <p>At the end of the day, the final judge of the LLM is a human. </p> <p>A number of sets of questions can be made and the LLM evaluated against them by a domain expert.</p> <p>Whilst a numerical rating system is the immediate choice, there are many flaws with this.</p> <p>The domain expert can rate the repsonse for the following:</p> <ol> <li>Accuracy. Is the answer factually correct?</li> <li>Relevance. Is the answer relevant to the question?</li> <li>Completeness. Is the answer complete?</li> <li>Clarity. Is the answer clear?</li> </ol> <p>Only those that get a YES to ACCURACY and RELEVANCE will be considered as they are essential for a good response.</p> <p>This is a very effective way of evaluating the LLM and will help us to improve our system and will be modiofied in the future as needed.</p>"},{"location":"evaluation/rate_with_llm/","title":"LLM as judge","text":"<p>The technique of an (untested) LLm generating question/answer pairs to act as ground truths to then test an LLM seems illogical but current thinking states this is quite effective.</p> <p>This technique might be used by developers to improve the knowledge system as they work on it rather than getting human evaluations at every step.</p> <p>This is more of a development tool rather than final evalauation.</p>"},{"location":"evaluation/refine/","title":"Refining","text":"<p>Over time we will find what architecture works best for us.</p> <p>By recording users feedback, we will be able to improve our system as we will begin to see which architecture has the 'most votes' from our users.</p>"},{"location":"pipeline/cache_and_rate/","title":"User ratings","text":"<p>Once a user gets a final response, the user will have the option to rate the response. </p> <p>We will record if they give it a thumbs up or down and they can also add thier own comments/additions to the response.</p> <p>These are all saved in the database so that later when another user asks a question we can check if a similar one with a positive rating exists. This can be fouind very quickly and offered to the user with the option of requesting further information.</p> <p>We can see if other users adding ratings to cached results given to them is effective. In this way we get a community rating of answers to questions.</p> <p>When a cached response is offered to a user, they could see statistics of what others think of this answer.</p> <p>This is an established techincal feature of many article sites.</p> <p>A clever UI could make all this feedback data and additonal information clean and effective rather than cluttering up the page.</p>"},{"location":"pipeline/gather/","title":"Gathering Docs","text":"<p>We need to create our own indexed library of documentrs so that we know what information we have.</p> <p>These will be collated for a specific medical domain.</p> <p>It would be helpful to have metadata about each document to help with filtering and correct retrieval.</p> <p>Data types can include:</p> <ul> <li>PDFs of articles.</li> <li>Tabular data within these articles.</li> <li>Images within these articles that have a text summary.</li> <li>Word, Powerpoint and Excel documents.</li> <li>Audio and video files to create transcripts to text as well video analysis of sequential images that are then summarised with text.</li> </ul> <p>MULTIMODAL</p>"},{"location":"pipeline/generate/","title":"Generation","text":"<p>Finally, once all thge checks have been passed the LLM can pass the response to the user ready for user evaluation and feedback.</p>"},{"location":"pipeline/grade/","title":"Grading","text":"<p>We can use an AI Grading Agent to grade the quality of retrieved documents, check the response for hallucinations and other issues.</p> <p>This can be use at any stage in the pipeline.</p>"},{"location":"pipeline/ingest/","title":"Ingestion","text":"<p>Once we have our data that has been cleaned and formatted, we need to ingest it into our knowledge base. Ingestion is the process of taking data and converting it into a format that can be used by our knowledge base.</p> <p>This means creating vector embeddings for each chunk, (which is termed a Document and many Documents make a paper/pdf) and then indexing them into a vector database.</p>"},{"location":"pipeline/pre_query/","title":"PreQuery","text":"<p>We can process the query using a pre-query to increase the quality of retrieval;</p>"},{"location":"pipeline/pre_query/#multi_query","title":"Multi Query","text":"<p>We get the LLM to make N versions of the user query and then get all the unique documents for them.</p>"},{"location":"pipeline/pre_query/#hyde","title":"HyDE","text":"<p>Hypothetical document embeddings is a technique that creates a theoretical document when responding to a query, as opposed to using the query and its computed vector to directly seek in the vector database.</p>"},{"location":"pipeline/query/","title":"Query","text":"<p>With our retrieved documents and the user question, we can now add them to one of Promtpt Templates to send to the LLM to generate a response.</p> <p>We will have a number of Prompt Templates and when the user finally rates the response, we will be able to record which template, as well as all the other strategy parameters, enabling us to refine our system.</p> <p>This is where PROMPT ENGINEERING comes into play.</p>"}]}